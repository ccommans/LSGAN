{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544dc273-ebbe-460d-88bb-827536ec02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision.transforms import functional\n",
    "import matplotlib.pyplot as plt\n",
    "from model import Generator64, Discriminator64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e504ca6-bfdc-435c-acd0-7324df425be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(epoch, G, z_dim, nrow=10, ncol=10, samp_dir='data/generated/TINY'):\n",
    "    os.makedirs(samp_dir, exist_ok=True)\n",
    "\n",
    "    sample_z = torch.randn(nrow*ncol, z_dim, 1, 1, device=device)\n",
    "    samples = G(sample_z)\n",
    "    save_image(samples, os.path.join(samp_dir, 'epoch_%03d.png' % (epoch)), nrow=ncol, normalize=True, value_range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c79241-1bf6-4fa4-a439-3646e52e4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, train_loader, epochs, batch_size=64, lr=0.0002, z_dim=100, model_dir='model/tiny'):\n",
    "    D_optimizer = optim.Adam(D.parameters(), lr=lr)\n",
    "    G_optimizer = optim.Adam(G.parameters(), lr=lr)\n",
    "    \n",
    "    # LSGAN labels\n",
    "    a = 0\n",
    "    b = 1\n",
    "    c = 1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        D_running_loss = 0.0\n",
    "        G_running_loss = 0.0\n",
    "\n",
    "        for real_img, _ in train_loader:\n",
    "            real_img = real_img.to(device)\n",
    "\n",
    "            # random noise\n",
    "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "\n",
    "            # --------------------\n",
    "            # update discriminator\n",
    "            # --------------------\n",
    "\n",
    "            D_optimizer.zero_grad()\n",
    "\n",
    "            # real\n",
    "            D_real = D(real_img)\n",
    "            D_real_loss = torch.sum((D_real - b) ** 2)\n",
    "\n",
    "            # fake\n",
    "            fake_img = G(z)\n",
    "            D_fake = D(fake_img.detach())\n",
    "            D_fake_loss = torch.sum((D_fake - a) ** 2)\n",
    "\n",
    "            # minimizing loss\n",
    "            D_loss = 0.5 * (D_real_loss + D_fake_loss) / batch_size\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "            D_running_loss += D_loss.data.item()\n",
    "\n",
    "            # ----------------\n",
    "            # update generator\n",
    "            # ----------------\n",
    "            \n",
    "            G_optimizer.zero_grad()\n",
    "\n",
    "            fake_img = G(z)\n",
    "            D_fake = D(fake_img)\n",
    "            \n",
    "            G_loss = 0.5 * (torch.sum((D_fake - c) ** 2)) / batch_size\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            G_running_loss += G_loss.data.item()\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} | D Loss: {D_running_loss:.4f} | G Loss: {G_running_loss:.4f}\")\n",
    "\n",
    "        # generate image\n",
    "        G.eval()\n",
    "        generate(epoch, G, z_dim)\n",
    "\n",
    "    # final models\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(G.state_dict(), model_dir+'/generator.pth')\n",
    "    torch.save(D.state_dict(), model_dir+'/discriminator.pth')\n",
    "    print(\"models saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaa0a0-358f-45b8-a6be-c58702791610",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "lr = 0.0002\n",
    "path_to_data = 'data/tiny-imagenet-200/train'\n",
    "\n",
    "# dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_to_data, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "D = Discriminator64().to(device)\n",
    "G = Generator64(nz=z_dim).to(device)\n",
    "\n",
    "train(D, G, train_loader, epochs, batch_size, lr, z_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece176",
   "language": "python",
   "name": "ece176"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
