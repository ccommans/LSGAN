{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d7e94-c1e6-404a-bf19-7b733a5158f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision.transforms import functional\n",
    "from torcheval.metrics import FrechetInceptionDistance\n",
    "from model import Generator64, Discriminator64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81e54c-0513-4693-9c4b-76ef9df5081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(epoch, G, z_dim, nrow=10, ncol=10, samp_dir='data/generated/KTH-TIPS'):\n",
    "    os.makedirs(samp_dir, exist_ok=True)\n",
    "\n",
    "    sample_z = torch.randn(nrow*ncol, z_dim, 1, 1, device=device)\n",
    "    samples = G(sample_z)\n",
    "    save_image(samples, os.path.join(samp_dir, 'epoch_%03d.png' % (epoch)), nrow=ncol, normalize=True, value_range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7a405-663d-4fc9-ac25-ca4baff93620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, train_loader, epochs, batch_size=64, lr=0.0002, z_dim=100, model_dir='model/kth', fid=False):\n",
    "    D_optimizer = optim.Adam(D.parameters(), lr=lr)\n",
    "    G_optimizer = optim.Adam(G.parameters(), lr=lr)\n",
    "    \n",
    "    # LSGAN labels\n",
    "    a = 0\n",
    "    b = 1\n",
    "    c = 1\n",
    "\n",
    "    fid_metric = FrechetInceptionDistance().to(device)\n",
    "\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    d_real_means = []\n",
    "    d_fake_means = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        D_running_loss = 0.0\n",
    "        G_running_loss = 0.0\n",
    "        fid_metric.reset()\n",
    "        \n",
    "        for real_img, _ in train_loader:\n",
    "            real_img = real_img.to(device)\n",
    "            real_img_fid = (real_img + 1) / 2  \n",
    "            fid_metric.update(real_img_fid, is_real=True)\n",
    "\n",
    "            # random noise\n",
    "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "            fake_img = G(z)\n",
    "            fake_img_fid = (fake_img + 1) / 2  \n",
    "            fid_metric.update(fake_img_fid, is_real=False)\n",
    "\n",
    "            # --------------------\n",
    "            # update discriminator\n",
    "            # --------------------\n",
    "\n",
    "            D_optimizer.zero_grad()\n",
    "\n",
    "            # real\n",
    "            D_real = D(real_img)\n",
    "            D_real_loss = torch.sum((D_real - b) ** 2)\n",
    "\n",
    "            # fake\n",
    "            D_fake = D(fake_img.detach())\n",
    "            D_fake_loss = torch.sum((D_fake - a) ** 2)\n",
    "\n",
    "            # minimizing loss\n",
    "            D_loss = 0.5 * (D_real_loss + D_fake_loss) / batch_size\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "            D_running_loss += D_loss.data.item()\n",
    "\n",
    "            # ----------------\n",
    "            # update generator\n",
    "            # ----------------\n",
    "            \n",
    "            G_optimizer.zero_grad()\n",
    "\n",
    "            D_fake = D(fake_img)\n",
    "            \n",
    "            G_loss = 0.5 * (torch.sum((D_fake - c) ** 2)) / batch_size\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            G_running_loss += G_loss.data.item()\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} | D Loss: {D_running_loss:.4f} | G Loss: {G_running_loss:.4f}\")\n",
    "\n",
    "        # generate image\n",
    "        G.eval()\n",
    "        generate(epoch, G, z_dim)\n",
    "        G.train()\n",
    "\n",
    "        if fid and epoch % 5 == 0:\n",
    "            fid_value = fid_metric.compute().item()\n",
    "            print(f\"Epoch {epoch}: FID = {fid_value:.2f}\")\n",
    "\n",
    "\n",
    "    # final models\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(G.state_dict(), model_dir+'/generator.pth')\n",
    "    torch.save(D.state_dict(), model_dir+'/discriminator.pth')\n",
    "    print('models saved')\n",
    "    \n",
    "    return d_losses, g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def1ea6-c4e2-4cdd-894d-90b43cfbccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "lr = 0.0002\n",
    "path_to_data = 'data/kth-tips'\n",
    "\n",
    "# augment dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_to_data, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "D = Discriminator64().to(device)\n",
    "G = Generator64(nz=z_dim).to(device)\n",
    "\n",
    "train(D, G, train_loader, epochs, batch_size, lr, z_dim, fid=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece176",
   "language": "python",
   "name": "ece176"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
